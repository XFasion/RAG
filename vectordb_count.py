import os
from dotenv import load_dotenv
from llama_index.embeddings.huggingface import HuggingFaceEmbedding
from llama_index.core import StorageContext, load_index_from_storage, Settings

# í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ
load_dotenv()
HF_TOKEN = os.getenv("HF_TOKEN")

# âœ… HuggingFace ì„ë² ë”© ëª¨ë¸ ëª…ì‹œ ì„¤ì •
embed_model = HuggingFaceEmbedding(
    model_name="nlpai-lab/KURE-v1",
    device="cpu",
    token=HF_TOKEN
)
Settings.embed_model = embed_model  # ğŸ”‘ ì´ê²Œ í•µì‹¬!

# ì €ì¥ëœ ë²¡í„° DB ë¡œë“œ
storage_context = StorageContext.from_defaults(persist_dir="./faiss_conversation_db_expanded")
index = load_index_from_storage(storage_context)

# ë²¡í„° ìŠ¤í† ì–´ ì ‘ê·¼
vector_store = index.vector_store
embedding_count = len(vector_store._data.embedding_dict)
print(f"ğŸ” í˜„ì¬ ë²¡í„° DBì— ì €ì¥ëœ ë¬¸ì¥ ìˆ˜: {embedding_count}")