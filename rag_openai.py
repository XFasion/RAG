import os
import time
from llama_index.core import (
    StorageContext,
    load_index_from_storage,
    Settings
)
from llama_index.embeddings.huggingface import HuggingFaceEmbedding
from openai import OpenAI
from dotenv import load_dotenv

from rag_prompt import RAG_PROMPT
from yusiyeon import CHARACTER_PROMPT 
os.environ["TOKENIZERS_PARALLELISM"] = "false" # ë³‘ë ¬ì²˜ë¦¬ ë¹„í™œì„±í™”

# í™˜ê²½ë³€ìˆ˜ ë¡œë“œ
load_dotenv()
HF_TOKEN = os.getenv("HF_TOKEN")
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")

# ì„ë² ë”© ëª¨ë¸ ì„¤ì •
embed_model = HuggingFaceEmbedding(
    model_name="nlpai-lab/KURE-v1",
    device="cpu",
    token=HF_TOKEN
)

Settings.embed_model = embed_model

# FAISS ì¸ë±ìŠ¤ ë¡œë“œ
storage_context = StorageContext.from_defaults(persist_dir="./faiss_conversation_db_expanded")
index = load_index_from_storage(storage_context)

# Retriever ì„¤ì •
retriever = index.as_retriever(similarity_top_k=3)
retriever.embed_model = embed_model

# OpenAI í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
client = OpenAI(api_key=OPENAI_API_KEY)

# ì§ˆë¬¸ì— ë‹µí•˜ëŠ” í•¨ìˆ˜ ì •ì˜
def query_rag(question):
    start_retrieve = time.time()
    nodes = retriever.retrieve(question)
    retrieve_time = time.time() - start_retrieve
 
    knowledge = "\n".join(node.text for node in nodes)

    print("\nâœ… ê²€ìƒ‰ëœ ë¬¸ì„œ:\n", knowledge)
    print(f"\nâ±ï¸ ê²€ìƒ‰(retrieve) ì†Œìš”ì‹œê°„: {retrieve_time:.4f} ì´ˆ")

    prompt = RAG_PROMPT.format(
        character_prompt=CHARACTER_PROMPT,
        related_conversations=knowledge,
        user_question=question
    )
    start_llm = time.time()

    response = client.chat.completions.create(
        model="gpt-4o",
        messages=[{"role": "user", "content": prompt}],
        max_tokens=800,
        temperature=0.8
    )
    llm_time = time.time() - start_llm
    print(f"â±ï¸ LLM ì‘ë‹µ ìƒì„± ì†Œìš”ì‹œê°„: {llm_time:.4f} ì´ˆ")

    return response.choices[0].message.content.strip()

# ì§ˆë¬¸ í…ŒìŠ¤íŠ¸
questions = [
    "ë„ˆ ë™ë¬¼ ë¬´ì„­ë‹¤ê³  ë‚œë¦¬ ì³¤ì—ˆì–ì•„ ê·¸ë•Œ ê¸°ì–µë‚˜?"
]

for question in questions:
    answer = query_rag(question)
    print(f"\nâ“ì§ˆë¬¸: {question}\nğŸ‘‰ë‹µë³€: {answer}")
